---
layout: single
title: "첫 포스팅"
---
## ML 과정
해당 페이지는 udemy 의 machinge learning 강의 내용들을 정리하여 가장 기초적인 기법부터 복습하는 목적으로 만들어졌습니다. 먼저 Machine Learning의 전체적인 과정을 살펴보겠습니다. 

**데이터 전처리**
- 데이터 가져오기
- 데이터 정리하기(clean)
- train set 와 test set으로 나누기

**모델링**
- 모델 빌드
- 모델 학습 시키기
- 예측 실행

**평가하기**
- metric 수치 계산하기
- 평결(verdict)를 만들기

위 와 같이 ML은 크게 세 과정으로 나뉘는데 가장 첫 번째 과정인 데이터 전처리의 기본부터 살펴보겠습니다.

## training set와 test set으로 나누기
data set을 굳이 두 개로 나누는 이유는 무엇일까요?
training set의 경우 주어진 data set의 정보를 학습시켜서 모델을 구축하는 것이 이유이고
test set의 경우 구축한 모델의 성능을 확인하기 위해서입니다. 

![image](https://github.com/minshik0705/algorithm_python/assets/112872144/fa4b8b16-4d48-48be-894d-98369b76ce9b)

가령, 위와 같이 주어진 data set을 80% train, 20% test set으로 나누었다고 가정합시다. 이때, 80%의 training set으로 선형회귀(linear regression) 기법으로 모델을 구축합니다. 이후에 구축한 모델에 20%의 test set을 적용하여 예측한 $\hat{y}$와 test set의 실제 관측치 y와 비교할 수 있게 됩니다.
그리고 이 두 값의 비교를 통해 모델의 성능을 생각할 수 있게 됩니다.

## 변수 조정 /Feature Scaling
전처리 과정에서 변수의 영향력을 결정하는 중요한 단계입니다.
말 그대로 변수의 크기/범위를 조정하는 과정인데 이것이 필요한 이유가 무엇일까요? 
data set의 변수들이 서로 다른 범위로 인해 데이터를 분석하는데 극단적인 영향력으로 인해 발생하는 문제들을 방지하기 위함입니다. 다음의 수입과 나이 data set 예시를 보겠습니다.


![image](https://github.com/minshik0705/algorithm_python/assets/112872144/de138fce-b2fe-4133-a12a-e6b59eb4907c)

위의 경우 우리는 보라돌이의 입장에서 빨강이와 8000$ 정도의 수입차이가 나기 때문에 10000$ 차이가 나는 파랑이와 비교했을 때 더 가까운 관계라고 생각할 수 있습니다. 물론 나이차이는 파랑이와 더욱 가깝지만 이는 1이라는 아주 미미한 차이이기에 신경을 쓸 필요가 없습니다. 하지만 우리는 이러한 해석이 잘못되었음을 직관적으로 압니다. 이를 증명하기 위해서 만약에 시간의 단위가 해가 아닌 분또는 초였다면, 오히려 달러보다 훨씬 큰 수칙가 나오게 됩니다.
이러한 영향력의 차이를 최대한 줄여주는 전처리 과정이 feature scaling입니다. 가장 대표적인 기법은 다음과 같이 두 가지 입니다.


![image](https://github.com/minshik0705/algorithm_python/assets/112872144/4bac2297-5ba6-4fe8-bf13-596e800fba62)
왼쪽은 min-max 정규화라 하고 해당 변수(data set의 열)의 각 값을 최소 값으로 빼고 최대 Max와 최소 Min의 차이로 나눈 기법입니다. 
따라서 범위는 [0;1]
오른쪽 표준화는 정규화와 비슷하지만 평균으로 빼고 표준편차로 나눈 기법입니다.
대체로 범위는 [-3;3]이지만 극단적인 측정치로 인해 더 클 수도 있습니다.

![image](https://github.com/minshik0705/algorithm_python/assets/112872144/cf30432c-5f46-41c0-b95f-60e500c20ade)
전에 보았던 예시에서 정규화를 이용하여 두번수의 수치를 보다 객관적으로 해석한 결과입니다. 이를 통해서 보라돌이와 파랑이의 변수의 차이가 더 작았음을 알 수 있죠
